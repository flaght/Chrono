import os, pdb, asyncio, time
from typing import Dict, List
from joblib import Parallel, delayed

from dotenv import load_dotenv

load_dotenv()

from alphacopilot.calendars.api import advanceDateByCalendar
from dichaos.battle.environment import AsyncBattleEnvironment
from dichaos.battle.state import BattleState
from agent.agents import Agents
from agent import IndicatorPredict, CloutoPredict, MoneyFlowPredict
from agent.decision.agent import DecisionAgent
from kdutils.report import ReportGenerator


async def run_concurrent_predictions(model_date: str, end_date: str,
                                     symbol: str):
    predictors = [
        CloutoPredict(date=model_date,
                      memory_path=os.path.join("records"),
                      symbol=symbol),
        IndicatorPredict(date=model_date,
                         memory_path=os.path.join("records"),
                         symbol=symbol),
        MoneyFlowPredict(date=model_date,
                         memory_path=os.path.join("records"),
                         symbol=symbol)
    ]

    end_date = advanceDateByCalendar('china.sse', end_date,
                                     '-{0}b'.format(1)).strftime('%Y-%m-%d')

    ### ä¸²è¡Œæ•°æ®å‡†å¤‡
    for p in predictors:
        p.prepare_data(begin_date=end_date, end_date=end_date)

    ### å¹¶å‘
    tasks = [
        p.agenerate_prediction(date=end_date,
                               predict_data=p.create_data(date=end_date))
        for p in predictors
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # å¤„ç†å¹¶æ”¶é›†ç»“æœ
    analysis_reports = {}  # key æ˜¯ agent.name, value æ˜¯åˆ†ææŠ¥å‘Šå­—ç¬¦ä¸²
    reason_reports = {}
    predictor_agents = []

    for pred, result in zip(predictors, results):
        agent_name = pred.agent.name
        predictor_agents.append(pred.agent)  # æ”¶é›† Agent å®ä¾‹

        summary = getattr(result, 'summary', str(result.summary))

        reason = getattr(result, 'reasoning', str(result.reasoning))

        analysis_details = getattr(result, 'analysis_details',
                                   str(result.analysis_details))

        analysis_reports[agent_name] = "{0} {1}".format(
            analysis_details, summary)

        reason_reports[agent_name] = reason

        print(f"ğŸ“Š æ¥è‡ª {pred.agent.name} çš„åˆ†æ")

    return analysis_reports, reason_reports, predictor_agents


async def run_agent_debate(symbol: str, initial_reports_map: Dict[str, str],
                           predictor_agents: List[Agents]):
    print("âš”ï¸ é˜¶æ®µäºŒ: å¤ç”¨ Agent è¿›è¡Œåšå¼ˆä¸å†³ç­– âš”ï¸")
    environment = AsyncBattleEnvironment(debate_rounds=5)

    for agent_instance in predictor_agents:
        agent_name = agent_instance.name
        role = agent_instance.desc()
        initial_analysis_for_agent = initial_reports_map.get(
            agent_name, "æˆ‘æ²¡æœ‰ç”Ÿæˆåˆå§‹åˆ†æã€‚")
        environment.register_agent(agent=agent_instance,
                                   role_description=role,
                                   initial_analysis=initial_analysis_for_agent)

    # å°†æ‰€æœ‰æŠ¥å‘Šæ±‡æ€»ï¼Œä½œä¸ºè¾©è®ºçš„å…¨å±€ä¸Šä¸‹æ–‡
    report_str = "\n".join([
        f"- **{report_name}**: {report_text}"
        for report_name, report_text in initial_reports_map.items()
    ])
    research_report = {
        "symbol": symbol,
        "preliminary_analysis_summary": report_str
    }

    # å¯åŠ¨è¾©è®º
    final_results = await environment.run(research_report)
    return final_results


async def run_final_decision(decision_agent: DecisionAgent,
                             battle_state: BattleState, symbol: str,
                             date: str):
    print("ğŸ“ é˜¶æ®µä¸‰: æœ€ç»ˆå†³ç­–åˆæˆ ğŸ“")
    # 1. æ ¼å¼åŒ–è¾©è®ºå†å²ä¸ºå•ä¸ªå­—ç¬¦ä¸²
    debate_transcript = []
    current_round = 0
    for event in battle_state['debate_history']:
        #if event["round"] != current_round and event["round"] == 3:
        if event["round"] == 3 or event["round"] == 4 or event["round"] == 5:
            current_round = event["round"]
            debate_transcript.append(f"\n--- ç¬¬ {current_round} è½® ---")
            debate_transcript.append(f'{event["speaker"]}: {event["content"]}')

    full_transcript = "\n".join(debate_transcript)
    print("ğŸ“œ è¾©è®ºè®°å½•æ‘˜è¦: {0}".format(full_transcript))

    final_prediction = await decision_agent.agenerate_prediction(
        debate_transcript=full_transcript, symbol=symbol, date=date)
    return final_prediction


# å°†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´å¤„ç†æµç¨‹å°è£…æˆä¸€ä¸ªç‹¬ç«‹çš„å¼‚æ­¥å‡½æ•°
async def process_single_symbol_workflow(symbol: str, model_date: str,
                                         end_date: str):
    """
    å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´ä¸‰é˜¶æ®µå·¥ä½œæµã€‚
    """
    try:
        print(f"ğŸš€ å¼€å§‹å¤„ç†è‚¡ç¥¨: {symbol}...")
        start_time = time.time()

        # --- æå‰åˆå§‹åŒ–å†³ç­– Agent ---
        # æ³¨æ„ï¼šå¦‚æœ DecisionAgent çš„åŠ è½½æ˜¯ I/O å¯†é›†å‹ï¼Œä¹Ÿå¯ä»¥åœ¨åç¨‹ä¸­åš
        decision_agent = DecisionAgent.from_config(
            path=os.path.join('agent', DecisionAgent.name))

        # --- é˜¶æ®µä¸€ï¼šå¹¶å‘é¢„æµ‹ ---
        initial_analysis_map, reason_reports, predictor_agents = await run_concurrent_predictions(
            model_date=model_date, end_date=end_date, symbol=symbol)

        # --- é˜¶æ®µäºŒï¼šå¤šæ™ºèƒ½ä½“è¾©è®º ---
        final_battle_state = await run_agent_debate(
            symbol=symbol,
            initial_reports_map=initial_analysis_map,
            predictor_agents=predictor_agents)

        # --- é˜¶æ®µä¸‰ï¼šæœ€ç»ˆå†³ç­– ---
        final_prediction = await run_final_decision(
            decision_agent=decision_agent,
            battle_state=final_battle_state,
            symbol=symbol,
            date=end_date)

        # --- é˜¶æ®µå››ï¼šç”ŸæˆæŠ¥å‘Š ---
        report_data = {
            "date": end_date,
            "symbol": symbol,
            "final_prediction": final_prediction.model_dump(),
            "battle_results": final_battle_state,
            "reason_reports": reason_reports
        }

        report = ReportGenerator(
            output_dir=os.path.join("records", "report", "html"),
            template_name=os.path.join("resource", "report_template.html"))
        # å‡è®¾ report.run() æ˜¯åŒæ­¥çš„ã€‚å¦‚æœæ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ await
        report.run(report_data=report_data)

        elapsed_time = time.time() - start_time
        print(f"âœ… æˆåŠŸå¤„ç†è‚¡ç¥¨: {symbol}ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        return {
            "symbol": symbol,
            "status": "success",
            "duration": elapsed_time
        }

    except Exception as e:
        elapsed_time = time.time() - start_time if 'start_time' in locals(
        ) else 0
        print(f"âŒ å¤„ç†è‚¡ç¥¨: {symbol} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return {
            "symbol": symbol,
            "status": "failed",
            "error": str(e),
            "duration": elapsed_time
        }


def run_workflow_entrypoint(symbol, model_date, end_date):
    """
    è¿™ä¸ªåŒæ­¥å‡½æ•°æ˜¯ ProcessPoolExecutor è°ƒç”¨çš„ç›®æ ‡ã€‚
    å®ƒçš„ä½œç”¨æ˜¯å¯åŠ¨ asyncio äº‹ä»¶å¾ªç¯æ¥è¿è¡Œæˆ‘ä»¬çš„å¼‚æ­¥å·¥ä½œæµã€‚
    """
    #symbol, model_date, end_date = args_tuple
    return asyncio.run(
        process_single_symbol_workflow(symbol, model_date, end_date))


import numpy as np
from joblib import cpu_count


def _get_n_jobs(n_jobs):
    """Get number of jobs for the computation.

    This function reimplements the logic of joblib to determine the actual
    number of jobs depending on the cpu count. If -1 all CPUs are used.
    If 1 is given, no parallel computing code is used at all, which is useful
    for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used.
    Thus for n_jobs = -2, all CPUs but one are used.

    Parameters
    ----------
    n_jobs : int
        Number of jobs stated in joblib convention.

    Returns
    -------
    n_jobs : int
        The actual number of jobs as positive integer.

    """
    if n_jobs < 0:
        return max(cpu_count() + 1 + n_jobs, 1)
    elif n_jobs == 0:
        raise ValueError('Parameter n_jobs == 0 has no meaning.')
    else:
        return n_jobs


def partition_estimators(n_estimators, n_jobs):
    """Private function used to partition estimators between jobs."""
    # Compute the number of jobs
    n_jobs = min(_get_n_jobs(n_jobs), n_estimators)

    # Partition estimators between jobs
    n_estimators_per_job = (n_estimators // n_jobs) * np.ones(n_jobs,
                                                              dtype=np.int32)
    n_estimators_per_job[:n_estimators % n_jobs] += 1
    starts = np.cumsum(n_estimators_per_job)

    return n_jobs, n_estimators_per_job.tolist(), [0] + starts.tolist()


if __name__ == "__main__":
    symbols_to_process = [
        '601519', '600519', '000001', '000002', '300750', '688981'
    ][:5]

    population = Parallel(n_jobs=4, verbose=1)(
        delayed(run_workflow_entrypoint)(symbols_to_process[i], '2025-01-27',
                                         '2025-02-14') for i in range(4))
