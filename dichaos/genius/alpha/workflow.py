import os, pdb, asyncio, time
import pandas as pd
from typing import Dict, List
from joblib import Parallel, delayed
from urllib.parse import urlparse
from pymongo import InsertOne, DeleteOne

from dotenv import load_dotenv

load_dotenv()

from alphacopilot.calendars.api import advanceDateByCalendar
from dichaos.battle.environment import AsyncBattleEnvironment
from dichaos.battle.state import BattleState
from agent.agents import Agents
from agent import IndicatorPredict, CloutoPredict, MoneyFlowPredict, ChipPredict, HotMoneyPredict
from agent.decision.agent import DecisionAgent
from kdutils.report import ReportGenerator
from kdutils.mongo import MongoLoader

mongo_client = MongoLoader(connection_string=os.environ['MG_URL'],
                           db_name=urlparse(
                               os.environ['MG_URL']).path.lstrip('/'),
                           collection_name='chat_history1')


async def predict_with_semaphore(predictor, semaphore: asyncio.Semaphore,
                                 date: str):
    """
    ä¸€ä¸ªå¼‚æ­¥åŒ…è£…å‡½æ•°ï¼Œå®ƒåœ¨ä½¿ç”¨ predictor è¿›è¡Œé¢„æµ‹ä¹‹å‰ï¼Œä¼šå…ˆä» semaphore è·å–è®¸å¯ã€‚
    
    Args:
        predictor: ä¸€ä¸ª Predictor ç±»çš„å®ä¾‹ (ä¾‹å¦‚ CloutoPredict)ã€‚
        semaphore (asyncio.Semaphore): ç”¨äºæ§åˆ¶å¹¶å‘çš„ä¿¡å·é‡ã€‚
        date (str): é¢„æµ‹æ—¥æœŸã€‚

    Returns:
        The result of the prediction or the exception if it fails.
    """
    # 3. åœ¨åŒ…è£…åç¨‹å†…è·å– Semaphore
    # async with è¯­å¥ç¡®ä¿äº†å³ä½¿åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼Œä¿¡å·é‡ä¹Ÿæ€»èƒ½è¢«æ­£ç¡®é‡Šæ”¾ã€‚
    async with semaphore:
        # å½“åç¨‹æ‰§è¡Œåˆ°è¿™é‡Œæ—¶ï¼Œå®ƒå·²ç»æˆåŠŸè·å–äº†ä¸€ä¸ªâ€œä»¤ç‰Œâ€ã€‚
        # å¦‚æœä»¤ç‰Œå·²æ»¡ï¼Œå®ƒä¼šåœ¨ä¸Šä¸€è¡Œå¼‚æ­¥åœ°ç­‰å¾…ã€‚
        print(f"[{predictor.agent.name}] è·å–åˆ°ä¿¡å·é‡è®¸å¯ï¼Œå¼€å§‹æ‰§è¡Œé¢„æµ‹...")

        try:
            # æ‰§è¡Œå®é™…çš„é¢„æµ‹è°ƒç”¨
            result = await predictor.agenerate_prediction(
                date=date, predict_data=predictor.create_data(date=date))
            return result
        except Exception as e:
            # æ•è·å¹¶è¿”å›å¼‚å¸¸ï¼Œè¿™æ · gather å°±ä¸ä¼šä¸­æ–­
            print(f"[{predictor.agent.name}] é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return e


async def run_concurrent_predictions2(model_date: str, end_date: str,
                                      symbol: str):
    MAX_CONCURRENT_REQUESTS = 2
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

    print(f"ä¿¡å·é‡å·²åˆ›å»ºï¼Œæœ€å¤§å¹¶å‘é¢„æµ‹æ•°ä¸º: {MAX_CONCURRENT_REQUESTS}")

    predictors = [
        CloutoPredict(date=model_date,
                      memory_path=os.path.join("records"),
                      symbol=symbol),
        IndicatorPredict(date=model_date,
                         memory_path=os.path.join("records"),
                         symbol=symbol)
    ]

    end_date = advanceDateByCalendar('china.sse', end_date,
                                     '-{0}b'.format(1)).strftime('%Y-%m-%d')

    for p in predictors:
        p.prepare_data(begin_date=end_date, end_date=end_date)

    # åˆ›å»ºä¸€ä¸ªä»»åŠ¡åˆ—è¡¨ï¼Œè¿™æ¬¡è°ƒç”¨çš„æ˜¯æˆ‘ä»¬çš„åŒ…è£…å‡½æ•° predict_with_semaphore
    tasks = [
        predict_with_semaphore(p, semaphore, end_date) for p in predictors
    ]
    print("å·²åˆ›å»ºæ‰€æœ‰å¹¶å‘ä»»åŠ¡ï¼Œå‡†å¤‡ä½¿ç”¨ asyncio.gather è¿è¡Œ...")
    results = await asyncio.gather(*tasks)
    # å¤„ç†å¹¶æ”¶é›†ç»“æœ
    analysis_reports = {}  # key æ˜¯ agent.name, value æ˜¯åˆ†ææŠ¥å‘Šå­—ç¬¦ä¸²
    reason_reports = {}
    predictor_agents = []

    for pred, result in zip(predictors, results):
        agent_name = pred.agent.name
        predictor_agents.append(pred.agent)  # æ”¶é›† Agent å®ä¾‹

        summary = getattr(result, 'summary', str(result.summary))

        reason = getattr(result, 'reasoning', str(result.reasoning))

        analysis_details = getattr(result, 'analysis_details',
                                   str(result.analysis_details))

        analysis_reports[agent_name] = "{0} {1}".format(
            analysis_details, summary)

        reason_reports[agent_name] = reason

        print(f"ğŸ“Š æ¥è‡ª {pred.agent.name} çš„åˆ†æ")

    return analysis_reports, reason_reports, predictor_agents


async def run_concurrent_predictions1(model_date: str, end_date: str,
                                      symbol: str):
    predictors = [
        CloutoPredict(date=model_date,
                      memory_path=os.path.join("records"),
                      symbol=symbol),
        IndicatorPredict(date=model_date,
                         memory_path=os.path.join("records"),
                         symbol=symbol),
        MoneyFlowPredict(date=model_date,
                         memory_path=os.path.join("records"),
                         symbol=symbol),
        ChipPredict(date=model_date,
                    memory_path=os.path.join("records"),
                    symbol=symbol),
        HotMoneyPredict(date=model_date,
                        memory_path=os.path.join("records"),
                        symbol=symbol)
    ]

    end_date = advanceDateByCalendar('china.sse', end_date,
                                     '-{0}b'.format(1)).strftime('%Y-%m-%d')

    ### ä¸²è¡Œæ•°æ®å‡†å¤‡
    for p in predictors:
        p.prepare_data(begin_date=end_date, end_date=end_date)

    ### å¹¶å‘
    tasks = [
        p.agenerate_prediction(date=end_date,
                               predict_data=p.create_data(date=end_date))
        for p in predictors
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # å¤„ç†å¹¶æ”¶é›†ç»“æœ
    analysis_reports = {}  # key æ˜¯ agent.name, value æ˜¯åˆ†ææŠ¥å‘Šå­—ç¬¦ä¸²
    reason_reports = {}
    predictor_agents = []

    for pred, result in zip(predictors, results):
        agent_name = pred.agent.name
        predictor_agents.append(pred.agent)  # æ”¶é›† Agent å®ä¾‹

        summary = getattr(result, 'summary', str(result.summary))

        reason = getattr(result, 'reasoning', str(result.reasoning))

        analysis_details = getattr(result, 'analysis_details',
                                   str(result.analysis_details))

        analysis_reports[agent_name] = "{0} {1}".format(
            analysis_details, summary)

        reason_reports[agent_name] = reason

        print(f"ğŸ“Š æ¥è‡ª {pred.agent.name} çš„åˆ†æ")

    return analysis_reports, reason_reports, predictor_agents


async def run_agent_debate(symbol: str,
                           initial_reports_map: Dict[str, str],
                           predictor_agents: List[Agents],
                           debate_rounds=4):
    print("âš”ï¸ é˜¶æ®µäºŒ: å¤ç”¨ Agent è¿›è¡Œåšå¼ˆä¸å†³ç­– âš”ï¸")
    environment = AsyncBattleEnvironment(debate_rounds=debate_rounds)

    for agent_instance in predictor_agents:
        agent_name = agent_instance.name
        role = agent_instance.desc()
        initial_analysis_for_agent = initial_reports_map.get(
            agent_name, "æˆ‘æ²¡æœ‰ç”Ÿæˆåˆå§‹åˆ†æã€‚")
        pdb.set_trace()
        environment.register_agent(llm_provider=agent_instance.llm_provider,
                                   agent=agent_instance,
                                   role_description=role,
                                   initial_analysis=initial_analysis_for_agent)

    # å°†æ‰€æœ‰æŠ¥å‘Šæ±‡æ€»ï¼Œä½œä¸ºè¾©è®ºçš„å…¨å±€ä¸Šä¸‹æ–‡
    report_str = "\n".join([
        f"- **{report_name}**: {report_text}"
        for report_name, report_text in initial_reports_map.items()
    ])
    research_report = {
        "symbol": symbol,
        "preliminary_analysis_summary": report_str
    }

    # å¯åŠ¨è¾©è®º
    final_results = await environment.run(research_report)
    return final_results


async def run_final_decision(decision_agent: DecisionAgent,
                             battle_state: BattleState, symbol: str, date: str,
                             debate_rounds: int):
    print("ğŸ“ é˜¶æ®µä¸‰: æœ€ç»ˆå†³ç­–åˆæˆ ğŸ“")
    # 1. æ ¼å¼åŒ–è¾©è®ºå†å²ä¸ºå•ä¸ªå­—ç¬¦ä¸²
    debate_transcript = []
    current_round = 0
    for event in battle_state['debate_history']:
        #if event["round"] != current_round and event["round"] == 3:
        if event["round"] in [
                debate_rounds, debate_rounds - 1, debate_rounds - 2
        ]:
            current_round = event["round"]
            debate_transcript.append(f"\n--- ç¬¬ {current_round} è½® ---")
            debate_transcript.append(f'{event["speaker"]}: {event["content"]}')

    full_transcript = "\n".join(debate_transcript)
    print("ğŸ“œ è¾©è®ºè®°å½•æ‘˜è¦: {0}".format(full_transcript))

    final_prediction = await decision_agent.agenerate_prediction(
        debate_transcript=full_transcript, symbol=symbol, date=date)
    return final_prediction


# å°†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´å¤„ç†æµç¨‹å°è£…æˆä¸€ä¸ªç‹¬ç«‹çš„å¼‚æ­¥å‡½æ•°
async def process_single_symbol_workflow2(symbol: str, model_date: str,
                                          end_date: str, debate_rounds: int):
    """
    å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´ä¸‰é˜¶æ®µå·¥ä½œæµã€‚
    """
    #try:
    print(f"ğŸš€ å¼€å§‹å¤„ç†è‚¡ç¥¨: {symbol}...")
    start_time = time.time()

    # --- æå‰åˆå§‹åŒ–å†³ç­– Agent ---
    # æ³¨æ„ï¼šå¦‚æœ DecisionAgent çš„åŠ è½½æ˜¯ I/O å¯†é›†å‹ï¼Œä¹Ÿå¯ä»¥åœ¨åç¨‹ä¸­åš
    decision_agent = DecisionAgent.from_config(
        path=os.path.join('agent', DecisionAgent.name))

    # --- é˜¶æ®µä¸€ï¼šå¹¶å‘é¢„æµ‹ ---
    initial_analysis_map, reason_reports, predictor_agents = await run_concurrent_predictions2(
        model_date=model_date, end_date=end_date, symbol=symbol)

    # --- é˜¶æ®µäºŒï¼šå¤šæ™ºèƒ½ä½“è¾©è®º ---
    final_battle_state = await run_agent_debate(
        symbol=symbol,
        initial_reports_map=initial_analysis_map,
        predictor_agents=predictor_agents,
        debate_rounds=debate_rounds)

    # --- é˜¶æ®µä¸‰ï¼šæœ€ç»ˆå†³ç­– ---
    final_prediction = await run_final_decision(
        decision_agent=decision_agent,
        battle_state=final_battle_state,
        symbol=symbol,
        date=end_date,
        debate_rounds=debate_rounds)

    # --- é˜¶æ®µå››ï¼šç”ŸæˆæŠ¥å‘Š ---
    report_data = {
        "date": end_date,
        "symbol": symbol,
        "final_prediction": final_prediction.model_dump(),
        "battle_results": final_battle_state,
        "reason_reports": reason_reports
    }
    pdb.set_trace()
    base_path = "/workspace/worker/temp/nginx/opts/dichaos/stock"
    report = ReportGenerator(output_dir=os.path.join(base_path, str(end_date),
                                                     "report", "html"),
                             template_name=os.path.join(
                                 "resource", "report_template.html"))
    # å‡è®¾ report.run() æ˜¯åŒæ­¥çš„ã€‚å¦‚æœæ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ await
    report.run(report_data=report_data)

    elapsed_time = time.time() - start_time
    print(f"âœ… æˆåŠŸå¤„ç†è‚¡ç¥¨: {symbol}ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
    return {
        "symbol": symbol,
        "status": "success",
        "duration": elapsed_time,
        "report_data": report_data
    }
    '''
    except Exception as e:
        elapsed_time = time.time() - start_time if 'start_time' in locals(
        ) else 0
        print(f"âŒ å¤„ç†è‚¡ç¥¨: {symbol} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            "symbol": symbol,
            "status": "failed",
            "error": str(e),
            "duration": elapsed_time
        }
    '''


# å°†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´å¤„ç†æµç¨‹å°è£…æˆä¸€ä¸ªç‹¬ç«‹çš„å¼‚æ­¥å‡½æ•°
async def process_single_symbol_workflow1(symbol: str, model_date: str,
                                          end_date: str, debate_rounds: int):
    """
    å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´ä¸‰é˜¶æ®µå·¥ä½œæµã€‚
    """
    try:
        print(f"ğŸš€ å¼€å§‹å¤„ç†è‚¡ç¥¨: {symbol}...")
        start_time = time.time()

        # --- æå‰åˆå§‹åŒ–å†³ç­– Agent ---
        # æ³¨æ„ï¼šå¦‚æœ DecisionAgent çš„åŠ è½½æ˜¯ I/O å¯†é›†å‹ï¼Œä¹Ÿå¯ä»¥åœ¨åç¨‹ä¸­åš
        decision_agent = DecisionAgent.from_config(
            path=os.path.join('agent', DecisionAgent.name))

        # --- é˜¶æ®µä¸€ï¼šå¹¶å‘é¢„æµ‹ ---
        initial_analysis_map, reason_reports, predictor_agents = await run_concurrent_predictions1(
            model_date=model_date, end_date=end_date, symbol=symbol)

        # --- é˜¶æ®µäºŒï¼šå¤šæ™ºèƒ½ä½“è¾©è®º ---
        final_battle_state = await run_agent_debate(
            symbol=symbol,
            initial_reports_map=initial_analysis_map,
            predictor_agents=predictor_agents,
            debate_rounds=debate_rounds)

        # --- é˜¶æ®µä¸‰ï¼šæœ€ç»ˆå†³ç­– ---
        final_prediction = await run_final_decision(
            decision_agent=decision_agent,
            battle_state=final_battle_state,
            symbol=symbol,
            date=end_date,
            debate_rounds=debate_rounds)

        # --- é˜¶æ®µå››ï¼šç”ŸæˆæŠ¥å‘Š ---
        report_data = {
            "date": end_date,
            "symbol": symbol,
            "final_prediction": final_prediction.model_dump(),
            "battle_results": final_battle_state,
            "reason_reports": reason_reports
        }
        base_path = "/workspace/worker/temp/nginx/opts/dichaos/stock"
        report = ReportGenerator(
            output_dir=os.path.join(base_path, str(end_date), "report",
                                    "html"),
            template_name=os.path.join("resource", "report_template.html"))
        # å‡è®¾ report.run() æ˜¯åŒæ­¥çš„ã€‚å¦‚æœæ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ await
        report.run(report_data=report_data)

        elapsed_time = time.time() - start_time
        print(f"âœ… æˆåŠŸå¤„ç†è‚¡ç¥¨: {symbol}ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        return {
            "symbol": symbol,
            "status": "success",
            "duration": elapsed_time,
            "report_data": report_data
        }

    except Exception as e:
        elapsed_time = time.time() - start_time if 'start_time' in locals(
        ) else 0
        print(f"âŒ å¤„ç†è‚¡ç¥¨: {symbol} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return {
            "symbol": symbol,
            "status": "failed",
            "error": str(e),
            "duration": elapsed_time
        }


def run_workflow_entrypoint(symbol, model_date, end_date):
    """
    è¿™ä¸ªåŒæ­¥å‡½æ•°æ˜¯ ProcessPoolExecutor è°ƒç”¨çš„ç›®æ ‡ã€‚
    å®ƒçš„ä½œç”¨æ˜¯å¯åŠ¨ asyncio äº‹ä»¶å¾ªç¯æ¥è¿è¡Œæˆ‘ä»¬çš„å¼‚æ­¥å·¥ä½œæµã€‚
    """
    #symbol, model_date, end_date = args_tuple
    return asyncio.run(
        process_single_symbol_workflow2(symbol, model_date, end_date, 2))


import numpy as np
from joblib import cpu_count


def _get_n_jobs(n_jobs):
    """Get number of jobs for the computation.

    This function reimplements the logic of joblib to determine the actual
    number of jobs depending on the cpu count. If -1 all CPUs are used.
    If 1 is given, no parallel computing code is used at all, which is useful
    for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used.
    Thus for n_jobs = -2, all CPUs but one are used.

    Parameters
    ----------
    n_jobs : int
        Number of jobs stated in joblib convention.

    Returns
    -------
    n_jobs : int
        The actual number of jobs as positive integer.

    """
    if n_jobs < 0:
        return max(cpu_count() + 1 + n_jobs, 1)
    elif n_jobs == 0:
        raise ValueError('Parameter n_jobs == 0 has no meaning.')
    else:
        return n_jobs


def partition_estimators(n_estimators, n_jobs):
    """Private function used to partition estimators between jobs."""
    # Compute the number of jobs
    n_jobs = min(_get_n_jobs(n_jobs), n_estimators)

    # Partition estimators between jobs
    n_estimators_per_job = (n_estimators // n_jobs) * np.ones(n_jobs,
                                                              dtype=np.int32)
    n_estimators_per_job[:n_estimators % n_jobs] += 1
    starts = np.cumsum(n_estimators_per_job)

    return n_jobs, n_estimators_per_job.tolist(), [0] + starts.tolist()


def update_data(results, table_name):
    delete_requests = [
        DeleteOne(message)
        for message in results[['symbol', 'trade_date']].to_dict(
            orient='records')
    ]

    insert_requests = [
        InsertOne(message) for message in results.to_dict(orient='records')
    ]

    requests = delete_requests + insert_requests

    mongo_client.bulk(requests=requests,
                      collection_name="{0}".format(table_name))


if __name__ == "__main__":
    symbols_to_process = [
        '001400', '605303', '002871', '000782', '603320', '605068', '000892',
        '601798', '002674', '002981', '002343', '002164', '600400', '603211',
        '002708', '000796', '001339', '002334', '002733', '600654', '603950',
        '600226', '000561'
    ][10:]
    symbols_to_process = ['601609']
    symbols_to_process = symbols_to_process

    end_date = '2025-08-20'  ## é¢„æµ‹çš„æ—¶é—´
    results = Parallel(n_jobs=1,
                       verbose=1)(delayed(run_workflow_entrypoint)(
                           symbols_to_process[i], '2025-01-27', end_date)
                                  for i in range(len(symbols_to_process)))
    pdb.set_trace()
    results = pd.DataFrame(results)
    results['trade_date'] = end_date
    update_data(results=results, table_name='genius_debate')
